function pathIntegratorNet()


% switches
% "plasticity": this is the plasticity on the lateral connection layer 
%     "HebbianRecurrent": hebbian plasticity on the recurrent 
%           parameters:
%               deltaJ: plasticity increment, it is normalized by the
%               standard deviation of the synaptic matrix elements
%     "None": no plasticity, the lateral connection are fixed
% "SynapticMatrix": the initial structure of the matrix
%     "LoadJComp": Load the synaptic matrix generated by the simulation HexLearn
%     "Load": load a pre-wired synaptic matrix with a mexican-hat structure, in the file SMatrix  
%     "MexicanHat" generate a mexican hat structure (and save it in the
%          file SMatrix. Cells are placed on the points of a square grid
%    "TriangularPeriodic": generate a matrix wher cells are placed at
%          random on a triangular grid. Mexican hat connections are produced with the periodicity. Asymmetric 
%          connections are added to create the path itnegation mechanism
%   "Random": random synapses, fractionActiveSynapses are active and distributed exponentially, normalized so that 
%          each row sum up on average to 1
% "Initialization": initial state of network activity
%    "ToMap": initialize the network in a state where only cells in the center of grid
%         cell are active.  This is still a bit of a problem: the system takes a while to settle on
%          the activity packet-attractor
%    "Random": random activity 
%    "GridTemplate": A template grid is established on the lower level, and
%         "trasfered to the simulated layer through the feedforward
%         connections

%Simulation = 'TriangularPathIntegrator';
Simulation = 'HexAdapt';
%Simulation = 'HexLearn';
%Simulation = 'FormedGrid';

switch Simulation
    
    
    % Simulation in which a layer "learns " the configurations of a
    % shifting hex grid through the connections that have been shaped by
    % competitive learning.  Lateral connections have hebbian learning
    case 'HexLearn'
        plasticity = 'HebbianRecurrent';
        synapticMatrix = 'Random';
        %synapticMatrix = 'Load';

        initialization = 'Random';
        outputDisplay = 'VideoImage';
        VideoFeatures = {};
        output = 'None';
        
        externalInput = 'GridPlace';

        InhibitionType = 'FixedActivity';

        %%%% parameters for the simulations

        latticeSpacing = 40; % unit is "centimeters"
        connectionSpan = 3; % the spread of the conncetion matrix

        N = 2500;  % the number of cells
        nSteps =200000; % the number of random walk steps
        cageSize = 100; % the size of the rat "cage"
        G =5; % the gain of the threshold-linear function
        threshold = 0.5; % the threshold of the threshold-linear function

        fixAct = 3; % the maximum average activity allowed by the inhibition mechanism
        gamma = 1; % the relative importance of the asymmetric component in the synapric matrix
        dT = 1; % time step at each iteration (a bit redundant, in practise we keep it at one)
        tau = 50; % the time constant

        dirStrength =8; % the strength of the directional input

        rampInputStrength = 10;

        constInputStrength = 2;
        placeInputStrength = 0.2;
        % neural adaptation is modeled as a subtractive term that
        %depends on the activity in the last Tadapt time steps (linearly decaying) and
        % with a strength Kadapt: A = - (Kadapt/Tadapt) \int_{t-Tadapt}^{t} dt' V(t') (t'-t+Tadapt)
        Tadapt = 50;
        Kadapt = 0.;

        
        % the learning coefficient
        deltaJ = 0.00001;
        fractionActiveSynapses = 0.1; % at the beginning
        side = 50;
        % we save the activity every monitorStep time steps
        monitorStep = 10;
        nondirInput = 0;



    
    % in this simulation, a mexical hat layer is spontaneously active,
    % adaption moves the grid around 
    case 'HexAdapt'
        tVideoInit = 300;
        tVideoEnd = 500;
        plasticity = 'None';

        output = 'None';
        %synapticMatrix = 'MexicanHat';
        boundaryConditions = 'Periodic';
        unitsArrangement = 'Square';
        
        synapticMatrix = 'Load';
        
        initialization = 'TuringLoad';
        %initialization = 'Random';
        outputDisplay = 'None';
        VideoFeatures = {};
        %externalInput = 'RampUpDown';
        externalInput = 'ConstantRandom';
        InhibitionType = 'FixedActivity';

        %%%% parameters for the simulations

        latticeSpacing = 40; % unit is "centimeters"
        connectionSpan = 3; % the spread of the conncetion matrix

        N = 2500;  % the number of cells
        nSteps =100000; % the number of random walk steps
        cageSize = 50; % the size of the rat "cage"
        G =5 % the gain of the threshold-linear function
        threshold = 0.5; % the threshold of the threshold-linear function

        fixAct = 6; % the maximum average activity allowed by the inhibition mechanism
        gamma = 0; % the relative importance of the asymmetric component in the synapric matrix
        dT = 1; % time step at each iteration (a bit redundant, in practise we keep it at one)
        tau = 50; % the time constant

        dirStrength =8; % the strength of the directional input

        %rampInputStrength = 10;
        rampInputStrengthStart = 1;
        rampInputStrength = 2;
        constInputStrength = 1;
        randInputStrength = 0.8;
        smoothLength = 500;
        placeInputStrength = 0.2;
        side = 50;
        
        % neural adaptation is modeled as a subtractive term that
        %depends on the activity in the last Tadapt time steps (linearly decaying) and
        % with a strength Kadapt: A = - (Kadapt/Tadapt) \int_{t-Tadapt}^{t} dt' V(t') (t'-t+Tadapt)
        Tadapt = 2000;
        Kadapt = 0.05;

        % we save the activity every monitorStep time steps
        monitorStep = 20;

        %%%%
        outputLayerConn = 0.02; % the conncetivity level for the output matrix  from Ole's layer
        Nout = 2500; % the number of units in the output layer
        deltaJComp = 0.1;
         nonDirInput = 0;
        
    % simulation for testing of the formed "learned" grid cell layer   
    case 'FormedGrid'

        plasticity = 'None';

        output = 'None';
        %synapticMatrix = 'MexicanHat';
        synapticMatrix = 'LoadJComp';
        
        initialization = 'Random';

        outputDisplay = 'FiringRateMaps';
        VideoFeatures = {};
        externalInput = '2DPlace';

        InhibitionType = 'FixedActivity';

        %%%% parameters for the simulations

        latticeSpacing = 40; % unit is "centimeters"
        connectionSpan = 3; % the spread of the conncetion matrix

        N = 2500;  % the number of cells
        nSteps =120000; % the number of random walk steps
        cageSize = 50; % the size of the rat "cage"
        G =3; % the gain of the threshold-linear function
        threshold = 0.2; % the threshold of the threshold-linear function

        fixAct = 6; % the maximum average activity allowed by the inhibition mechanism
        gamma = 0; % the relative importance of the asymmetric component in the synapric matrix
        dT = 1; % time step at each iteration (a bit redundant, in practise we keep it at one)
        tau = 50; % the time constant

        dirStrength =8; % the strength of the directional input

        rampInputStrength = 10;

        constInputStrength = 0.1;

        % neural adaptation is modeled as a subtractive term that
        %depends on the activity in the last Tadapt time steps (linearly decaying) and
        % with a strength Kadapt: A = - (Kadapt/Tadapt) \int_{t-Tadapt}^{t} dt' V(t') (t'-t+Tadapt)
        Tadapt = 50;
        Kadapt = 1.;

        % we save the activity every monitorStep time steps
        monitorStep = 20;

        %%%%
        outputLayerConn = 0.02; % the conncetivity level for the output matrix  from Ole's layer
        Nout = 2500 % the number of units in the output layer
        deltaJComp = 0.1;
        
        % parameters for the 2DPlace input situation
        Ninp = 400; % the number of units in the input layer
        inputActivationSpread = 3; % the "place field size" in the ipnut layer (the larger, the more correlated inputs for neighboring
        % positions will be
        placeInputStrength = 0.4;
         nonDirInput = 0;
         
    case 'TriangularPathIntegrator'
        % this caused OK path integration but, a lot of transition to "head
        % direction" state

        synapticMatrix = 'TriangularPeriodic';

        initialization = 'ToMap';

        outputDisplay = 'Video';
        tVideoInit = 60;
        tVideoEnd = 500;

        externalInput = 'HeadDirection';

        plasticity = 'None';

        output = 'None';

        InhibitionType= 'FixedActivity';

        VideoFeatures = {'RatVideo'};
        %%%% parameters for the simulations

        latticeSpacing = 40; % unit is "centimeters"
        connectionSpan = 7.5; % the spread of the conncetion matrix

        N = 2500;  % the number of cells
        nSteps =400000; % the number of random walk steps
        cageSize = 100; % the size of the rat "cage"
        G = 50; % the gain of the threshold-linear function
        threshold = 0.5; % the threshold of the threshold-linear function

        fixAct = 2; % the maximum average activity allowed by the inhibition mechanism
        gamma = 1.1; % the relative importance of the asymmetric component in the synapric matrix
        dT = 1; % time step at each iteration (a bit redundant, in practise we keep it at one)
        tau = 50; % the time constant

        dirStrength = 8; % the strength of the directional input
        nonDirInput = 0;


        % neural adaptation is modeled as a subtractive term that
        %depends on the activity in the last Tadapt time steps (linearly decaying) and
        % with a strength Kadapt: A = - (Kadapt/Tadapt) \int_{t-Tadapt}^{t} dt' V(t') (t'-t+Tadapt)
        Tadapt = 500;
        Kadapt = 0.5;

        % we save the activity every monitorStep time steps
        monitorStep = 10;

end


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%


 % the preferred direction for each cell, uniformly distributed on [0, 2 \pi]
        phi = rand(1,N)*2*pi;


        % The versor for each cell
        dirCell = [cos(phi) ; sin(phi)];

switch synapticMatrix
    
    case 'Load'
        
        load SMatrix
        N = size(J, 1);
    case 'LoadJComp'
        load Jcomp
         % get rid of "autapses"
        for i = 1:N
            J(i,i) = 0;
        end
        
        J(find(J < 0)) = 0;
        % normalize J so that the rows sum on average to 1
         Jnorm = abs(mean(sum(J,2)))
         J = J / Jnorm;
         J(find(J > 1e-3)) = 1e-3;
    case 'MexicanHat'
        % draw point in a rectangle 
        
        
        switch unitsArrangement
            case 'Square'
                
                
        
                l = sqrt(N);

                xx = linspace(0, latticeSpacing, l+1);
                xx = xx(1:end-1) - latticeSpacing/2;
                yy = xx;
                [XX, YY]  = meshgrid(xx, yy);
                x = (XX(:))';
                y = (YY(:))';
                clear xx yy XX YY

            case 'Circle'
                
                latticeSpacing = latticeSpacing * 2 / sqrt(pi);
                incr = sqrt(pi*(latticeSpacing/2)^2/N);
                r = latticeSpacing/incr;
                xx = linspace(-latticeSpacing/2,latticeSpacing/2, r);
                x = [];
                y = [];
                for i = xx
                   yy = sqrt((latticeSpacing/2)^2 - (i).^2);
                   yy = -yy:incr:yy;
                   y = [y yy];
                   x = [x (i*ones(size(yy)))];
                end
                N = length(x);
                plot(x, y, '.');
                
        end
        
                
                
        [X, Y] = meshgrid(x,y);
        Y = Y';
        
        
        % notice that the only differnce between the triangular and the
        % square boundary conditions is the definition of the vectors (at
        % 90 degrees instead of 60
        J = zeros(N,N);
        v1 = [1, 0] * latticeSpacing;
        v2 = [0, 1] * latticeSpacing;
        
        if strcmp(boundaryConditions, 'Periodic')
            iSpan = -2:2;
            jSpan = -2:2;
        else
            iSpan = 0;
            jSpan = 0;
        end
        
        
        for i = iSpan
            for j = jSpan
                [XC, YC] = meshgrid(x+i*v1(1)+j*v2(1), ...
                    y+i*v1(2)+j*v2(2));
                XC = XC';
                XC = sqrt((X-XC).^2 + (Y-YC).^2);
                J = J + mexhat(XC, connectionSpan);
            end
        end
        
        clear X Y XC YC 
        % get rid of "autapses"
        for i = 1:N
            J(i,i) = 0;
        end
        % normalize J so that the rows sum on average to 1
         Jnorm = abs(mean(sum(J,2)))
         J = J / Jnorm;
         
        save SMatrix J x y 
   case 'TriangularPeriodic'


        % set up the place on the grid of  each cell, so that
        % they will be uniformly distributed in the triangular lattice



        nd = N;

        % first draw points in a equilateral triangle


        x = rand(1,N) - 0.5;
        y = rand(1, N) * sqrt(3) / 2;

        while(nd)
            % points falling outside the triangle)
            ndix = find(y > sqrt(3) * (x+0.5) | y  > -sqrt(3) * (x - 0.5));
            nd = length(ndix);
            x(ndix) = rand(1,nd)- 0.5;
            y(ndix) = rand(1,nd) * sqrt(3)/2;

        end


        % move half of the points in the symmetric triangle on the other side
        % of the X-axis

        y(floor(N/2):N) = -y(floor(N/2):N);
        x = x * latticeSpacing;
        y = y * latticeSpacing;
        
        axis equal


       


        % now compute synaptic matrix

        % to keep into accoutn the periodic conditions we need to sum terms
        % corresponding to several lattice basis vectors, in practice we get two on each
        % side, connections decay with a constant smaller than lattice spacing, so this
        % is
        J = zeros(N, N);

        % lattice basis vectors
        v1 = [1, 0] * latticeSpacing;
        v2 = [0.5, sqrt(3)/2] * latticeSpacing;


        % J_{ij} = (1 + \gamma \cos(phi_j - \atan(\vector{d_i} - \vector{d_j})))
        % exp(- | d_i - d_j | /latticeSpacing) + terms coming from the periodic
        % bondary conditions

        % a few meshgrid tricks to "vectorize" the synaptic matrix generation

        [X, Y] = meshgrid(x,y);
        Y = Y';
        [Phi,phiY] = meshgrid(phi,phi);
        for i = -2:2
            for j = -2:2
                [XC, YC] = meshgrid(x+i*v1(1)+j*v2(1), ...
                    y+i*v1(2)+j*v2(2));
                XC = XC';

                zeta = atan2(YC-Y, XC-X);

                D = sqrt((X-XC).^2 + (Y-YC).^2);
                J = J + (1 + gamma * cos(zeta-Phi)) .* exp(-D  /connectionSpan);
                %J = J + exp(-D * (1 )/connectionSpan);
                %          if i == 0 & j == 0
                %              keyboard
                %          end

            end
        end

        % get rid of "autapses"
        for i = 1:N
            J(i,i) = 0;
        end


        % normalize J so that the rows sum on average to 1
        Jnorm = mean(sum(J,2));
        J = J / Jnorm;
        
        figure
        imagesc(J);
        clear X Y XC YC zeta D Phi phiY
        save SMatrix J x y phi dirCell
       
    case 'Random'
        
        J = exprnd(1, N, N);
        jj = rand(N,N);
        J(find(jj< (1-fractionActiveSynapses))) = 0;
        % get rid of "autapses"
        for i = 1:N
            J(i,i) = 0;
        end
        % normalize J so that the rows sum on average to 1
        Jnorm = mean(sum(J,2));
        J = J / Jnorm;

end

 %%%% end synaptic matrix
 
 if strcmp(plasticity, 'HebbianRecurrent')
     deltaJCoeff = deltaJ * std(J(:));
 end
 
 if strcmp(externalInput, '2DPlace')
    % input is given by a layer of place cells with p.f.c.s on a 20x20 grid
    % the synapses from this layer to the grid cell layer are random with
    % exponential distribution
    
    l = sqrt(Ninp);

    xx = linspace(0, cageSize, l+1);
    xx = xx(1:end-1);
    yy = xx;
    [XX, YY]  = meshgrid(xx, yy);
    xInp = (XX(:));
    yInp = (YY(:));
    clear xx yy XX YY
    
    Jinp = rand( N, Ninp);
    
     
     
     ;
 end
 



 if strcmp(output, 'CompLearn')
     Jout = rand(Nout, N);
     Jout = reshape((Jout < outputLayerConn), Nout, N);
     Jnorm = mean(sum(Jout,2));
     Jout = Jout / Jnorm;
     Jcomp = zeros(Nout, Nout);
     
     vOutConf = zeros(Nout, floor(nSteps)/monitorStep);
 end
 
     
 
 
 Vi = zeros(N,1);
 Va = zeros(N, 10);
 Vadapt=zeros(N, Tadapt);
 

 switch initialization

     case 'ToMap'
         %initialize the network in a state where only cells in the center of grid
         %cell are active
         % this is still a bit of a problem: the system takes a while to settle on
         % the activity packet-attractor


         Vi = 3* exp(-sqrt((x).^2+(y).^2)/(latticeSpacing/10));
         Vi / mean(Vi) * fixAct;
         Vi = Vi';
     case 'Random'
         %Vi = 20 * exprnd(1, N, 1);
         Vi = 0.02* rand(N, 1);
     case 'GridTemplate'
         load gridTemplate
         side = 50;
         px = 1;
         py = 1;
         Vin = gridTemplate(px:(px+side-1),py:(py+side-1));
         Jcomp = Jcomp(ix,:);
          Jcomp = Jcomp/size(Jcomp, 2);
         Vi = placeInputStrength * Jcomp * Vin(:);
     case 'TuringLoad'
         load InitConf
 end

% save the history of the activity configurations
Vconf = zeros(N, floor(nSteps)/monitorStep, 'single');

% generate the rat trajectory
dbclear all
[xRat, yRat] = randomWalk(nSteps+500, cageSize);
xRat = xRat(501:end);
yRat = yRat(501:end);


% instantaneous rat speed 
vRat = [diff(xRat) ; diff(yRat)];

xRat = xRat(2:end);
yRat = yRat(2:end);

% for the adaptation calculation 
adaptScale = (linspace(0, Kadapt/Tadapt, Tadapt))';
mm = 0;

 if strcmp(externalInput, 'GridPlace')
         Jcomp = Jcomp/size(Jcomp, 2);
     Jcomp = Jcomp(ix,:);
     phaseX = ceil(xRat);
     phaseY = ceil(yRat);
 end
 
 
 if strcmp(externalInput, 'ConstantRandom')
    
    extInpTot = makeExtInp(N, 10000, randInputStrength, smoothLength);
 end 
tic

Ci = exp(-dT/tau);
CiM = 1 - Ci;
% main simulation loop
 for ns = 1:(nSteps-1)

     mm = mod(ns, Tadapt);
     if(mm == Tadapt)
         mm = 0;
     end

     % adaptation: Vadapt is a "ring buffer" so that we optimize away 
     as = [adaptScale(end-mm:end) ; adaptScale(1:(end-mm-1))];
     A = Vadapt * as;
    
    % save previous configuration
    Viold = Vi;
    
    
    switch externalInput
        case 'HeadDirection'
            % the directional input is proportional to the scalar product of the
            % speed and the directional versor of each cell 
            extInp = nonDirInput + dirStrength * ((vRat(:,ns))'*dirCell)';
            extInp(extInp < 0) = 0; % rectfy inputs
            
        case 'Ramp'
            extInp = ones(size(N)) *  (rampInputStrengthStart +(ns/nSteps) * (rampInputStrength-rampInputStrengthStart));
        case 'RampUpDown'
            if ns <= nSteps/2
                extInp = ones(size(N)) *  (rampInputStrengthStart +(ns/(nSteps/2) ) * ...
                    (rampInputStrength-rampInputStrengthStart));
            else 
                extInp = ones(size(N)) *  (rampInputStrengthStart +((nSteps-ns)/(nSteps/2) ) * ...
                    (rampInputStrength-rampInputStrengthStart));
            end
            
        case 'Constant'
            extInp = ones(size(N)) * constInputStrength;
            
        case 'ConstantRandom'
            q = mod(ns, 10000);
            if q == 0
                q = 10000;
            end
            extInp = ones(size(N)) * constInputStrength + extInpTot(:,q);
            if q == 10000
                extInpTot = makeExtInp(N, 10000, randInputStrength, smoothLength);
            end
            
        case '2DPlace'
            d = sqrt((xInp - xRat(ns)) .^ 2 +  (yInp - yRat(ns)).^2);
            extInp = constInputStrength + placeInputStrength * Jinp * exp(-d/inputActivationSpread);
            
        case 'GridPlace'
            load gridTemplate
            % we move to a different input phase every monitorStep steps
            if mod(ns, monitorStep) == 1
                px = phaseX(ceil(ns/monitorStep));
                py = phaseY(ceil(ns/monitorStep));
                Vin = gridTemplate(px:(px+side-1),py:(py+side-1));
                extInp = placeInputStrength * Jcomp * Vin(:);
            end
    end
    
    % compute input to each neuron: recurrent synaptic + directional input - adaptation 
    F = J * Vi + extInp - A;
    
    Vfield = max(G.*(F-threshold), 0);
    % compute activation without inhibition 
    Vi = CiM * Vfield + Ci * Viold;

    if(ns > 20)
        2;
    end
    
    
    switch InhibitionType
        case 'FixedActivity'
            
            % compute the global inhibition that will take the totla activity to
            % fixAct * N, the "sort" trick gets around the threshold-linear
            % nonlinearity
            VfieldThr= N * fixAct- Ci*sum(Viold);
            
            Vs = sort(Vfield);
            Vs = Vs(end:-1:1);
            Q = cumsum(Vs) - ((1:N)') .* Vs;

            Qix = min(find(Q > N*fixAct));
            
%             if isempty(Qix)
%                 Qix = 600;
%             end
            
           
            if isempty(Qix) & sum(Vi) > N * fixAct
                Qix = N;
            end
            Qix = min(Qix, 300);
            if isempty(Qix)
                inhib = 0;
            else
                inhib = Vs(Qix)/ (mean(G));
            end


            % now compute the "inhibited" activation
            F = F - inhib;
            Vi = CiM * max(G.*(F-threshold), 0) + Ci * Viold;
        case 'Noglobal'
            inhib = 0;
    end
    
    % save activity
    mm = mod(ns, monitorStep);
    if mm == 0
        mm = monitorStep;
    end
    Va(:,mm) = Vi;

    %every monitorStep steps average activtiy and store the result in Vconf
    if mm == monitorStep
        Vconf(:,ns/monitorStep) = mean(Va, 2);
        switch output
            case 'CompLearn'
                Fout = Jout * Vi;
                % simulate a "soft competitive learning" 
                Vout = (Fout-mean(Fout))/std(Fout);
                Vout= (1 ./ (1 + exp(-4*(Vout-2.1))));
                Jcomp = Jcomp + deltaJComp * (Vout-mean(Vout)) * (Vout-mean(Vout))';
             
                    
                Jcomp(find(Jcomp<0)) = 0;
                vOutConf(:,ns/monitorStep) = Vout;
%                  if ns > 500 
%                      keyboard
%                  end
                
        end
        
             
        switch plasticity
            case 'HebbianRecurrent'
                vv = mean(Va,2);
                z = (Vi-mean(Vi))/std(Vi);

                J  = J + deltaJCoeff * max(z*z', 0);
                for i = 1:N
                    J(i,i) = 0;
                end
                    
                    
                    
                    
            case 'None'
                ;
        end
    end

   
    
    if mod(ns, 50) == 0
        disp(ns);
        disp(sum(Vi)/N);
    end

%     if(ns > 500)
%        2 ;
%     end
%     
    
    % save buffer for adaptation

    ma = mod(ns, Tadapt);
    if ma == 0
        ma = Tadapt;
    end
    Vadapt(:,ma) = Vi;


        
 end
 

 toc
 
dx = dirCell(1,:);
dy = dirCell(2,:);

vr = vRat(:,1:monitorStep:end);
xx = xRat(1:monitorStep:end);
yy = yRat(1:monitorStep:end);

 np = 1;

 if strcmp(Simulation, 'HexLearn')
     save SMatrix J
 end
 
 save Vconf Vconf x  y monitorStep xRat yRat xx yy
 
 
 switch outputDisplay

     case 'FiringRateInfo'
         for phase = 1:nInfoSteps:nSteps
             vc = Vconf(:,phase:(phase+nInfoSteps-1));
             n = 1;
             for i = 1:10:N
                 fmap = ndAverage([xx;yy], vc(i,:), [40;40], [0;0], [cageSize; cageSize]);
                 fnorm = ndHist([xx;yy], [40;40], [0;0], [cageSize; cageSize]);
                 ix = find(isfinite(fmap) & fnorm > 0);
                 fmap = fmap(ix)+ eps;
                 fnorm = fnorm(ix);
                 frate = sum(fmap .* fnorm) / sum(fnorm);
                 I(phase,n) = sum(fmap.*log(fmap/frate) .* fnorm) / sum(fnorm); 
                 n = n+1;
                 
             end
             for i = 1:50:N
                 fmap = ndAverage([xx;yy], Vconf(i,:), [40;40], [0;0], [cageSize; cageSize]);
                 imagesc(fmap);
                 keyboard
             end
         end


     case 'FiringRateMaps'
         for i = 1:50:N
             fmap = ndAverage([xx;yy], Vconf(i,:), [40;40], [0;0], [cageSize; cageSize]);
             imagesc(fmap);
             keyboard
         end
         
     case 'VideoImage'
            
            tInit = 1;
            %tEnd = nSteps/monitorStep;
            tEnd = 5000/monitorStep;
            nConf = size(Vtot, 1);
            side  = sqrt(nConf);
            for i = tInit:10:tEnd
                vv = (Vconf(:,i))';
                vvk = repmat(vv, nConf,1);
                acPack = sum(Vtot .* vvk, 2);
                acPack = reshape(acPack, 50, 50);
                imagesc(acPack)
                hold on 
                text(20, 25, num2str(i));
                hold off 
                M(np) = getframe;
                np = np+1;
            end
            keyboard
         movie2avi(M, 'Packet.avi', 'FPS', 6, 'COMPRESSION', 'None');
     case 'Video'
           tInit = tVideoInit;
           tEnd = tVideoEnd;
           plotColors(x, y, Vconf(:,tVideoEnd), 15), axis equal 
           hold off
           keyboard
         %video generation
         for i = tInit:tEnd
             
             
             plotColors(x, y, Vconf(:,i), 15), axis equal % activation as a function of position on the grid
             hold on;
             
             axis([-40 40 -30 30]);
             if ismember('RatVideo', VideoFeatures)
                 plot(-30 + 10*cos(0:0.1:2*pi), 20 + 10* sin(0:0.1:2*pi)); % Rat inst. speed
                 plot([-30, -30+50*vr(1,i)], [20, 20+50*vr(2,i)])
                 plotColors(-30+10*dx, -20+10*dy, Vconf(:,i),15); % activation as a fucntion of directional preference
                 
                 % rat position
                 plot([20 40], [-10 -10 ]);
                 plot([20 20], [-10 -30]);
                 mi = max(i-50, tInit);
                 plot(xx(mi:i)/5+20, yy(mi:i)/5-30);
                 plot(xx(i)/5+20, yy(i)/5-30, 'r.');
             end
             text(20, 25, num2str(i));
             hold off
             M(np) = getframe;
             np = np+1;
         end
        
        save simOutput Vconf dirCell 
         movie2avi(M, 'Packet.avi', 'FPS', 6, 'COMPRESSION', 'None');
     case 'None'
         ;
 end

 
 if strcmp(output, 'CompLearn')
     save Jcomp Jcomp
     keyboard
 end
 
% shamelessly copied  from Ole 

function y = mexhat(x, sig)

y = (1 -  x.^2/sig^2).*exp(-x.^2 / (2*sig^2));


function y = mexhat2(x, sig1, sig2)

y = exp(-x.^2 / (2*sig1^2))/sig1 - (x.^2/sig2^2).*exp(-x.^2 / (2*sig2^2))/sig2;

function extInpTot = makeExtInp(N, nSteps, randInputStrength, smoothLength)
     nh = ceil(nSteps/smoothLength)
     extInpTot = rand(nh, N);
     extInpTot = (resample(extInpTot, nSteps, nh))';
     extInpTot(extInpTot < 0) = 0;
     eNorm = mean(extInpTot(:));
     extInpTot = extInpTot * randInputStrength / eNorm;
 

